{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "06526d06",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "d4b270fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"http://localhost:8001/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "00b2edb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "7942a920",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Hello World': 'from FastAPI'}\n"
     ]
    }
   ],
   "source": [
    "print(response.json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "0052741a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(R'C:\\Users\\caver\\Desktop\\Projetos_VS_Code\\Neurotech_API\\challenge-data-scientist\\monitoring\\batch_records.json') as f:\n",
    "    data = json.load(f)\n",
    "    \n",
    "url = \"http://localhost:8001/v1/performance/performance-volumetry\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "3dc71778",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.post(url, json=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "38e24468",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requisição bem-sucedida!\n"
     ]
    }
   ],
   "source": [
    "if response.status_code == 200:\n",
    "    print(\"Requisição bem-sucedida!\")\n",
    "else:\n",
    "    print(\"Erro na requisição:\", response.status_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "0238e398",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "    {\n",
      "        \"2017-01\": 6902,\n",
      "        \"2017-02\": 6545,\n",
      "        \"2017-03\": 7378,\n",
      "        \"2017-04\": 5831,\n",
      "        \"2017-05\": 7973,\n",
      "        \"2017-06\": 7497,\n",
      "        \"2017-07\": 8806,\n",
      "        \"2017-08\": 8568,\n",
      "        \"2017-09\": 0,\n",
      "        \"2017-10\": 0,\n",
      "        \"2017-11\": 0,\n",
      "        \"2017-12\": 0\n",
      "    },\n",
      "    \"valor da \\u00e1rea sob a curva ROC: \",\n",
      "    0.5751748251748252\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "print(json.dumps(response.json(), indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "9e79bb7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'> [{'path': 'C:/Users/caver/Desktop/Projetos_VS_Code/Neurotech_API/challenge-data-scientist/monitoring/train.csv'}]\n"
     ]
    }
   ],
   "source": [
    "#C:\\Users\\caver\\Desktop\\Projetos_VS_Code\\Neurotech_API\\challenge-data-scientist\\monitoring\\test.csv\n",
    "data = [  {    \"path\": \"C:/Users/caver/Desktop/Projetos_VS_Code/Neurotech_API/challenge-data-scientist/monitoring/train.csv\"  }]\n",
    "\n",
    "url = \"http://localhost:8001/v1/aderencia/aderencia\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "f4d9c090",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.post(url, json=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "0673b595",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requisição bem-sucedida!\n"
     ]
    }
   ],
   "source": [
    "if response.status_code == 200:\n",
    "    print(\"Requisição bem-sucedida!\")\n",
    "else:\n",
    "    print(\"Erro na requisição:\", response.status_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "f26281d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "    {\n",
      "        \"path\": \"C:/Users/caver/Desktop/Projetos_VS_Code/Neurotech_API/challenge-data-scientist/monitoring/train.csv\",\n",
      "        \"ks_stat\": 0.0005332048827709768,\n",
      "        \"p_value\": 1.0\n",
      "    }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "result = response.json()\n",
    "print(json.dumps(result, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "fb74b029",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [  {    \"path\": \"C:/Users/caver/Desktop/Projetos_VS_Code/Neurotech_API/challenge-data-scientist/monitoring/test.csv\"  }]\n",
    "\n",
    "url = \"http://localhost:8001/v1/aderencia/aderencia\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "f04f4018",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.post(url, json=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "0e932530",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requisição bem-sucedida!\n"
     ]
    }
   ],
   "source": [
    "if response.status_code == 200:\n",
    "    print(\"Requisição bem-sucedida!\")\n",
    "else:\n",
    "    print(\"Erro na requisição:\", response.status_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "c048a679",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "    {\n",
      "        \"path\": \"C:/Users/caver/Desktop/Projetos_VS_Code/Neurotech_API/challenge-data-scientist/monitoring/test.csv\",\n",
      "        \"ks_stat\": 0.0,\n",
      "        \"p_value\": 1.0\n",
      "    }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "result = response.json()\n",
    "print(json.dumps(result, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "d2ff3de1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Perguntas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "cef24c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1)\n",
    "# Pode dar problemas com muitas requisições, sim. Se houver muitas requisições ao mesmo tempo no mesmo endpoint, haverá uma\n",
    "# carga muito grande no servidor. Dito isso, a API pode parar de responder.\n",
    "\n",
    "# É possível evitar isso. A primeira solução seria a implementação de um cache. Poderíamos usar a tecnologia de cache\n",
    "# para armazenar os resultados de requisições recentes. Poderíamos verificar se o resultado já está armazenado no cache.\n",
    "# Caso isso seja verdade, poderíamos retornar o resultado armazenado em vez de realizar todo esse processo novamente.\n",
    "\n",
    "# Outra solução seria criar diversas APIs, e não apenas uma. O trabalho que uma API teria seria dividido com outras\n",
    "# implementações de diversas APIs. Isso pode melhorar ainda mais o monitoramento. Há centenas de testes que podem ser\n",
    "# efetuados, e todos esses testes não precisam ser efetuados no mesmo lugar.\n",
    "\n",
    "# Para evitar que a API seja muito utilizada e acabe tendo diversos impecilhos, poderia ser implementado também um limite\n",
    "# de requisições. Por exemplo, 500 requisições por 60 segundos. Quando alguém quiser usar e tiver muitas pessoas usando\n",
    "# essa API, retornaria algo do tipo \"Sistema sobrecarregado, tente outra API ou aguarde\".\n",
    "\n",
    "\n",
    "# 2) \n",
    "# Na produção, um problema mais crítico seria diversos ataques nos dados. Se algum hacker decidir atacar um dos modelos, \n",
    "# esse modelo pode começar a gerar dados com menos credibilidade. Uma possível solução seria investir em mecanismos de defesa.\n",
    "\n",
    "# Alterações nos dados de entrada podem afetar diretamente o desempenho do modelo em questão. Caso um modelo tenha sido \n",
    "# treinado para tirar insights das economias de uma empresa, se colocarmos esse modelo para dar insights de outra empresa\n",
    "# com uma grande crise, pode ser que sua performance seja prejudicada. É importante monitorar a distribuição dos dados de\n",
    "# entrada e checar se está tudo funcionando gradualmente com diferentes backgrounds.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e98a3a1e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
